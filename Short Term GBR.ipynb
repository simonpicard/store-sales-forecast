{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"data/features.csv\")\n",
    "historic_sales = pd.read_csv(\"data/train.csv\")\n",
    "store_info = pd.read_csv(\"data/stores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"Date\"] = pd.to_datetime(features[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historic_sales = historic_sales.sort_values(by=['Store', 'Dept', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (historic_sales[\"Dept\"] == '2011-04-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (historic_sales[\"Dept\"] == '2011-04-15')\n",
    "historic_sales.loc[idx,['Dept','Date', 'IsHoliday', 'Weekly_Sales']] = historic_sales.loc[idx,['Date','Dept', 'Weekly_Sales', 'IsHoliday']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historic_sales[\"Dept\"] = historic_sales[\"Dept\"].apply(lambda x: int(float(x.replace(\",\",\".\"))) if type(x) is str else x).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historic_sales[\"Weekly_Sales\"] = pd.to_numeric(historic_sales[\"Weekly_Sales\"].apply(lambda x: x.replace(\"nan\",\"\").replace(\",\",\".\") if type(x) is str else x ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historic_sales.loc[(historic_sales[\"Weekly_Sales\"]<0), \"Weekly_Sales\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillFirstLast(df):\n",
    "    for s in df[\"Store\"].unique():\n",
    "        for d in df[df[\"Store\"]==s][\"Dept\"].unique():\n",
    "\n",
    "            toFill = df[(df[\"Store\"]==s) & (df[\"Dept\"]==d)][\"Weekly_Sales\"].isnull()\n",
    "\n",
    "            i = 0\n",
    "            bfiller = None\n",
    "            index = None\n",
    "            while i < len(toFill)-1 and toFill.iloc[i]:\n",
    "                i += 1\n",
    "                bfiller = df[(df[\"Store\"]==s) & (df[\"Dept\"]==d)][\"Weekly_Sales\"].iloc[i]\n",
    "                index = df[(df[\"Store\"]==s) & (df[\"Dept\"]==d)].index[i]\n",
    "\n",
    "\n",
    "            if bfiller != None: \n",
    "                for j in range(index-i, index):\n",
    "                    df.loc[j, \"Weekly_Sales\"] = bfiller\n",
    "\n",
    "            i = len(toFill)-1\n",
    "            ffiller = None\n",
    "            index = None\n",
    "            while i > 0 and toFill.iloc[i]:\n",
    "                i -= 1\n",
    "                ffiller = df[(df[\"Store\"]==s) & (df[\"Dept\"]==d)][\"Weekly_Sales\"].iloc[i]\n",
    "                index = df[(df[\"Store\"]==s) & (df[\"Dept\"]==d)].index[i]\n",
    "\n",
    "            diff = len(toFill)-1-i\n",
    "            if ffiller != None: \n",
    "                for j in range(index+1, index+diff+1):\n",
    "                    df.loc[j, \"Weekly_Sales\"] = ffiller\n",
    "    return df\n",
    "\n",
    "historic_sales = fillFirstLast(historic_sales)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historic_sales[\"Weekly_Sales\"] = (historic_sales[\"Weekly_Sales\"].fillna(method='ffill') + historic_sales[\"Weekly_Sales\"].fillna(method='bfill'))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historic_sales[\"IsHoliday\"] = historic_sales[\"IsHoliday\"].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historic_sales[\"Date\"] = pd.to_datetime(historic_sales[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historic_sales = historic_sales.drop(193967)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_ewma_ctr = historic_sales.groupby([\"Store\", \"Dept\"]).agg({'Date': ['min','max']}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_ewma =  historic_sales.loc[:, ('Store', 'Dept', 'Date', 'Weekly_Sales')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missings = {'Store' : [], 'Dept' : [], 'Date' : [], 'Weekly_Sales' : []}\n",
    "for s in hs_ewma_ctr[\"Store\"].unique():\n",
    "    for d in hs_ewma_ctr[hs_ewma_ctr[\"Store\"]==s][\"Dept\"].unique():\n",
    "        idx = (hs_ewma_ctr[\"Store\"]==s)  & (hs_ewma_ctr[\"Dept\"]==d)\n",
    "        current = hs_ewma_ctr[idx]['Date']['min'].iloc[0]\n",
    "        last = hs_ewma_ctr[idx]['Date']['max'].iloc[0]\n",
    "        existing = historic_sales.loc[(historic_sales[\"Store\"]==s)  & (historic_sales[\"Dept\"]==d), \"Date\"]\n",
    "        #print(existing)\n",
    "        while current <= last:\n",
    "            if (existing == current).sum() == 0:\n",
    "                missings['Store'].append(s)\n",
    "                missings['Dept'].append(d)\n",
    "                missings['Date'].append(current)\n",
    "                missings['Weekly_Sales'].append(None)\n",
    "                #print(s, d, current)\n",
    "            current += timedelta(days=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missings = pd.DataFrame(missings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missings[\"Weekly_Sales\"] = pd.to_numeric(missings[\"Weekly_Sales\"])\n",
    "missings[\"Dept\"] = missings[\"Dept\"].astype('category')\n",
    "missings[\"Store\"] = missings[\"Store\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_ewma = hs_ewma.append(missings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_ewma = hs_ewma.sort_values(by=['Store', 'Dept', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_ewma.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_ewma[\"Weekly_Sales\"] = (hs_ewma[\"Weekly_Sales\"].fillna(method='ffill') + hs_ewma[\"Weekly_Sales\"].fillna(method='bfill'))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = hs_ewma.groupby([\"Store\", \"Dept\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_ewma[\"hist_1y\"] = grouped[\"Weekly_Sales\"].shift(52)\n",
    "hs_ewma[\"hist_1w\"] = grouped[\"Weekly_Sales\"].shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = hs_ewma.groupby([\"Store\", \"Dept\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_ewma[\"hist_2w\"] = grouped[\"hist_1w\"].shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spans = [4, 13, 52]\n",
    "cols = ['ewma_1m', 'ewma_3m', 'ewma_1y']\n",
    "\n",
    "for span, col in zip(spans, cols):\n",
    "\n",
    "    data = grouped[\"hist_1w\"].ewm(span=span).mean()\n",
    "    data.index = data.index.get_level_values(2)\n",
    "    hs_ewma[col] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_ewma[\"diff_1w\"] = grouped[\"hist_1w\"].diff()\n",
    "hs_ewma[\"diff_2w\"] = grouped[\"hist_2w\"].diff()\n",
    "hs_ewma[\"diff_1y\"] = grouped[\"hist_1w\"].diff(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spans = [4, 13, 52]\n",
    "cols = ['std_1m', 'std_3m', 'std_1y']\n",
    "\n",
    "for span, col in zip(spans, cols):\n",
    "\n",
    "    data = grouped[\"hist_1w\"].rolling(span).std()\n",
    "    data.index = data.index.get_level_values(2)\n",
    "    hs_ewma[col] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = hs_ewma.groupby([\"Store\", \"Dept\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_info[\"Type\"] = store_info[\"Type\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historic_sales_store_info = historic_sales.merge(store_info, how=\"left\", on=\"Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = historic_sales_store_info.merge(features, how=\"left\", on=(\"Store\", \"Date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(hs_ewma, how=\"left\", on=(\"Store\", \"Dept\", \"Date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Weekly_Sales\"] = df[\"Weekly_Sales_y\"]\n",
    "df[\"IsHoliday\"] = df[\"IsHoliday_x\"]\n",
    "df = df.drop(labels=['IsHoliday_x', 'IsHoliday_y', 'Weekly_Sales_x', 'Weekly_Sales_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"hasMD1\"] = df[\"MarkDown1\"].isnull().apply(lambda x : not(x))\n",
    "df[\"hasMD2\"] = df[\"MarkDown2\"].isnull().apply(lambda x : not(x))\n",
    "df[\"hasMD3\"] = df[\"MarkDown3\"].isnull().apply(lambda x : not(x))\n",
    "df[\"hasMD4\"] = df[\"MarkDown4\"].isnull().apply(lambda x : not(x))\n",
    "df[\"hasMD5\"] = df[\"MarkDown5\"].isnull().apply(lambda x : not(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"MarkDown1\"] = df[\"MarkDown1\"].fillna(0)\n",
    "df[\"MarkDown2\"] = df[\"MarkDown2\"].fillna(0)\n",
    "df[\"MarkDown3\"] = df[\"MarkDown3\"].fillna(0)\n",
    "df[\"MarkDown4\"] = df[\"MarkDown4\"].fillna(0)\n",
    "df[\"MarkDown5\"] = df[\"MarkDown5\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['Dept'], prefix=\"D\")], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['Type'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['Store'], prefix=\"S\")], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Month\"] = df[\"Date\"].apply(lambda x : x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Month\"] = df[\"Month\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['Month'], prefix=\"M\")], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTest(df, n):\n",
    "    grouped = df.groupby([\"Store\", \"Dept\"])\n",
    "    test = grouped.tail(n)\n",
    "    test.loc[:, \"Weekly_Sales_True\"] = test[\"Weekly_Sales\"]\n",
    "    test.loc[:, \"Weekly_Sales\"] = np.nan\n",
    "    \n",
    "    grouped = df.groupby([\"Store\", \"Dept\"], as_index=False)\n",
    "    train = grouped.apply(lambda x: x.iloc[:-n])\n",
    "    train.index = train.index.droplevel()\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = trainTest(df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(random_state=0, n_estimators=100, max_depth = 3, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_var = 'Weekly_Sales'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_var = ['Size', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'ewma_1m', 'ewma_3m', 'ewma_1y', 'hist_1y', 'hist_1w', 'diff_1w', 'diff_1y', 'std_1m', 'std_3m', 'std_1y', 'IsHoliday', 'hasMD1', 'hasMD2', 'hasMD3', 'hasMD4', 'hasMD5', 'D_1.0', 'D_2.0', 'D_3.0', 'D_4.0', 'D_5.0', 'D_6.0', 'D_7.0', 'D_8.0', 'D_9.0', 'D_10.0', 'D_11.0', 'D_12.0', 'D_13.0', 'D_14.0', 'D_16.0', 'D_17.0', 'D_18.0', 'D_19.0', 'D_20.0', 'D_21.0', 'D_22.0', 'D_23.0', 'D_24.0', 'D_25.0', 'D_26.0', 'D_27.0', 'D_28.0', 'D_29.0', 'D_30.0', 'D_31.0', 'D_32.0', 'D_33.0', 'D_34.0', 'D_35.0', 'D_36.0', 'D_37.0', 'D_38.0', 'D_40.0', 'D_41.0', 'D_42.0', 'D_44.0', 'D_45.0', 'D_46.0', 'D_47.0', 'D_48.0', 'D_49.0', 'D_50.0', 'D_51.0', 'D_52.0', 'D_54.0', 'D_55.0', 'D_56.0', 'D_58.0', 'D_59.0', 'D_60.0', 'D_65.0', 'D_67.0', 'D_71.0', 'D_72.0', 'D_74.0', 'D_77.0', 'D_78.0', 'D_79.0', 'D_80.0', 'D_81.0', 'D_82.0', 'D_83.0', 'D_85.0', 'D_87.0', 'D_90.0', 'D_91.0', 'D_92.0', 'D_93.0', 'D_94.0', 'D_95.0', 'D_96.0', 'D_97.0', 'D_98.0', 'D_99.0', 'A', 'B', 'C', 'S_1', 'S_2', 'S_3', 'S_4', 'S_5', 'S_6', 'S_7', 'S_8', 'S_9', 'S_10', 'S_11', 'S_12', 'S_13', 'S_14', 'S_15', 'S_16', 'S_17', 'S_18', 'S_19', 'S_20', 'S_21', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'S_27', 'S_28', 'S_29', 'S_30', 'S_31', 'S_32', 'S_33', 'S_34', 'S_35', 'S_36', 'S_37', 'S_38', 'S_39', 'S_40', 'S_41', 'S_42', 'S_43', 'S_44', 'S_45', 'M_1', 'M_2', 'M_3', 'M_4', 'M_5', 'M_6', 'M_7', 'M_8', 'M_9', 'M_10', 'M_11', 'M_12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(df[predictor_var],df[outcome_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Weekly_Sales_Pred\"] = model.predict(df[predictor_var])\n",
    "print(r2_score(df[\"Weekly_Sales\"], df[\"Weekly_Sales_Pred\"]))\n",
    "print(mean_squared_error(df[\"Weekly_Sales\"], df[\"Weekly_Sales_Pred\"])**0.5)\n",
    "print(mean_absolute_error(df[\"Weekly_Sales\"], df[\"Weekly_Sales_Pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train[predictor_var],train[outcome_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Weekly_Sales\"] = model.predict(test[predictor_var])\n",
    "print(r2_score(test[\"Weekly_Sales_True\"], test[\"Weekly_Sales\"]))\n",
    "print(mean_squared_error(test[\"Weekly_Sales_True\"], test[\"Weekly_Sales\"])**0.5)\n",
    "print(mean_absolute_error(test[\"Weekly_Sales_True\"], test[\"Weekly_Sales\"])**0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
